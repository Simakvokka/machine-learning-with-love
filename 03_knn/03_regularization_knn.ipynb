{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Введение в машинное обучение\n",
    "\n",
    "## Семинар #3\n",
    "\n",
    "### Екатерина Кондратьева\n",
    "\n",
    "ekaterina.kondrateva@skoltech.ru\n",
    "\n",
    "## Регуляризация в линейных моделях. Метод Ближайших Соседей (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Регуляризация в линейных моделях"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Регуляризация - наложение ограничения на решающае правило через нормы. Это нужно для борьбы с переобучением методом отбора признаков. \n",
    "\n",
    "Источники:\n",
    "1. https://github.com/esokolov/ml-course-hse/blob/master/2018-fall/lecture-notes/lecture03-linregr.pdf    \n",
    "2. http://www.machinelearning.ru/wiki/images/7/7e/VetrovSem11_LARS.pdf\n",
    "3. https://ru.coursera.org/lecture/supervised-learning/rieghuliarizatsiia-sR94Q\n",
    "4. https://towardsdatascience.com/regularization-in-machine-learning-connecting-the-dots-c6e030bfaddd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#linear algebra\n",
    "import numpy as np\n",
    "#data structures\n",
    "import pandas as pd\n",
    "#ml models\n",
    "import scipy as sp\n",
    "import sklearn\n",
    "from sklearn import datasets\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import SVR\n",
    "#plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "#beautiful plots\n",
    "import seaborn as sns\n",
    "#linear regression\n",
    "import statsmodels.api as sm\n",
    "#set style for plots\n",
    "sns.set_style('darkgrid')\n",
    "#off the warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.neighbors import KNeighborsClassifier     #KNN\n",
    "from sklearn.linear_model import LogisticRegression    #Logistic Regression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Начнем Логистической регрессии:\n",
    "\n",
    "Посмотрим на датасет предсказания рака груди:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the breast cancer data and few EDA\n",
    "cancer = load_breast_cancer()\n",
    "print(cancer.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разобьем выборку на обучающую и тестовую\n",
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, stratify=cancer.target, random_state=42)\n",
    "\n",
    "log_reg = LogisticRegression() \n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "print('Точность на обучающей выборке: {:.3f}'.format(log_reg.score(X_train,y_train)))\n",
    "print('Точность на тестовой выборке: {:.3f}'.format(log_reg.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.score(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = log_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_score(y_pred, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.data.shape, X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Посмотрим на коэффициенты модели:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cancer.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим график значимости признаков (веса регрессионной модели)\n",
    "n_feature = cancer.data.shape[1]\n",
    "plt.barh(range(n_feature), abs(log_reg.coef_[0]), align='center') # to look at the coefs\n",
    "plt.yticks(np.arange(n_feature), cancer.feature_names)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LogisticRegression(C= 0.1, penalty='l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какая регуляризация используется в модели?**\n",
    "\n",
    "Наиболее полная справка о построенной модели доступна в библиотеке `statsmodels.api`, однако в ней не поддреживаются некоторые регуляризации и их нужно прописывать формульно. В `statsmodels.api` вы можете получить полный вывод для составления уравнения регрессии, с p-value и интервалом достоверности, огранизованным в виде таблицы.\n",
    "\n",
    "\n",
    "Однако, чаще используется `sklearn.linear_model.LogisticRegression()`, в котором частично информацию можно получить через `.feature_importances` или `.coef`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# добавим константу, чтобы посчитать нулевой коэффициент\n",
    "X = sm.add_constant(X_train)\n",
    "# подгрузим модель\n",
    "model = sm.OLS(y_train, X)\n",
    "\n",
    "results = model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Построим график значимости признаков\n",
    "n_feature = cancer.data.shape[1]\n",
    "plt.barh(range(n_feature), results.params[1:], align='center') # to look at the coefs\n",
    "plt.yticks(np.arange(n_feature), cancer.feature_names)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Регуляризация"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L1 Lasso regularisation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Объяснение ближе к математическому: \n",
    "    https://stats.stackexchange.com/questions/45643/why-l1-norm-for-sparse-models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='l1') # посмотрим, что это значит в справке\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy on the training set: {:.3f}'.format(log_reg.score(X_train,y_train)))\n",
    "print('Accuracy on the test set: {:.3f}'.format(log_reg.score(X_test,y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# График значимости\n",
    "n_feature = cancer.data.shape[1]\n",
    "plt.barh(range(n_feature), log_reg.coef_[0], align='center') # to look at the coefs\n",
    "plt.yticks(np.arange(n_feature), cancer.feature_names)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Сколько осталось ненулевых весов в модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg.coef_[log_reg.coef_ != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(log_reg.coef_[log_reg.coef_!=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нужно ли стандартизовывать данные перед обучением и как это влияет на построение модели?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_sc = scaler.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# посмотрим на краевые значения\n",
    "X_train.max(), X_train.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_sc.max(), X_train_sc.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression() # check the model params\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy on the training set: {:.3f}'.format(log_reg.score(X_train,y_train)))\n",
    "print('Accuracy on the training set: {:.3f}'.format(log_reg.score(X_test,y_test)))\n",
    "\n",
    "#Feature Importance\n",
    "n_feature = cancer.data.shape[1]\n",
    "plt.barh(range(n_feature), log_reg.coef_[0], align='center') # to look at the coefs\n",
    "plt.yticks(np.arange(n_feature), cancer.feature_names)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_reg = LogisticRegression(penalty='l1', C=0.001) # вторая\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "print('Accuracy on the training set: {:.3f}'.format(log_reg.score(X_train,y_train)))\n",
    "print('Accuracy on the training set: {:.3f}'.format(log_reg.score(X_test,y_test)))\n",
    "\n",
    "#Feature Importance\n",
    "n_feature = cancer.data.shape[1]\n",
    "plt.barh(range(n_feature), log_reg.coef_[0], align='center') # to look at the coefs\n",
    "plt.yticks(np.arange(n_feature), cancer.feature_names)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Сколько осталось ненулевых коэффициентов после применения резуляризации?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(log_reg.coef_[log_reg.coef_!=0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Насколько мы можем верить тому, что на 3х признаках точность упала всего на 3%?\n",
    "\n",
    "Что если повторить эксперимент с регуляризацией на 5-10 различных разбиениях \n",
    "`random_seed` или на кросс-валидации? (ДЗ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic net (L1 & L2 regularisation):\n",
    "\n",
    "Пример работы совмещенной регуляризации, на практике применим только в специфичных задачах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.fit_regularized() # method='elastic_net'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Feature Importance\n",
    "n_feature = cancer.data.shape[1]\n",
    "plt.barh(range(n_feature), results.params[1:], align='center') # to look at the coefs\n",
    "plt.yticks(np.arange(n_feature), cancer.feature_names)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(results.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(range(n_feature), abs(results.params[1:]), align='center') # to look at the coefs\n",
    "plt.yticks(np.arange(n_feature), cancer.feature_names)\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Вопросы:\n",
    "\n",
    "- Помогла ли l1 \"жесткая\" регуляризация избежать переобучения?\n",
    "- Переобучилась ли модель на нескольких характеристиках?\n",
    "- Как это проверить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2. k Nearest Neighbors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "\n",
    "\n",
    "`Sklearn`:\n",
    "<a href='http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html'>Regressor</a>\n",
    "<a href='http://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html'>Classifier</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T16:18:35.634420Z",
     "start_time": "2018-08-01T16:18:32.928271Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Тренируем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T16:18:43.909285Z",
     "start_time": "2018-08-01T16:18:43.799059Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
    "\n",
    "\n",
    "#######\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "clf = KNeighborsClassifier()\n",
    "clf.fit(X_train, y_train)\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T15:22:07.852739Z",
     "start_time": "2018-08-01T15:22:07.843104Z"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 1. Метрики и ядерные функции:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Метрики, реализованные в `sklearn`:\n",
    "\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.DistanceMetric.html\n",
    "\n",
    "### Специальные метрики для токенизации в пакете:\n",
    "https://pypi.org/project/Distance/\n",
    "\n",
    "### Или здесь:\n",
    "\n",
    "http://www.nltk.org/_modules/nltk/align/bleu_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Какая метрика стоит по дефолту?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Классифицируем попарно для того, чтобы сделать отрисовку решающего правила. Это наглядный пример работы классификатора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T16:37:13.800932Z",
     "start_time": "2018-08-01T16:37:11.260639Z"
    },
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "pair=[0, 1]\n",
    "X = iris.data[:, [0, 1]]\n",
    "y = iris.target\n",
    "\n",
    "n_classes = 3\n",
    "plot_colors = ['g', 'gold', 'black']\n",
    "plot_step = 0.005\n",
    "\n",
    "x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, plot_step),\n",
    "                     np.arange(y_min, y_max, plot_step))\n",
    "\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=10).fit(X, y)\n",
    "\n",
    "Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "Z = Z.reshape(xx.shape)\n",
    "cs = plt.contourf(xx, yy, Z, cmap='Accent')\n",
    "\n",
    "plt.xlabel(iris.feature_names[pair[0]])\n",
    "plt.ylabel(iris.feature_names[pair[1]])\n",
    "\n",
    "for i, color in zip(range(n_classes), plot_colors):\n",
    "    idx = np.where(y == i)\n",
    "    plt.scatter(X[idx, 0], X[idx, 1], c=color, label=iris.target_names[i],\n",
    "                cmap=plt.cm.Paired)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.KNN Regression:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим на пример искусственных двумерных данных (оранжевый) и предсказание этих данных по координате с помощью метода `knn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-01T16:42:19.129848Z",
     "start_time": "2018-08-01T16:42:18.968192Z"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "rng = np.random.RandomState(1)\n",
    "X = np.sort(5 * rng.rand(80, 1), axis=0)\n",
    "y = np.sin(X).ravel()\n",
    "# y = np.piecewise(X.flatten(), \n",
    "#                  [X.flatten() < 3, X.flatten() >= 3], [-1, 1]).ravel()\n",
    "y[::2] += 1 * (0.5 - rng.rand(40))\n",
    "\n",
    "X_test = np.arange(0.0, 5.0, 0.01)[:, np.newaxis]\n",
    "\n",
    "# clf = KNeighborsRegressor(n_neighbors=30, \n",
    "#                           #weights=gaussian_kernel\n",
    "#                          ).fit(X, y)\n",
    "clf = LinearRegression().fit(X, y)\n",
    "\n",
    "y_ = clf.predict(X_test)\n",
    "plt.scatter(X, y, c='darkorange', label='data')\n",
    "plt.plot(X_test, y_, c='cornflowerblue', label='prediction');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Какое оптимальное число соседей `k`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"отбелим данные\"\n",
    "standardizer = StandardScaler()\n",
    "X_std = standardizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=5, metric='euclidean', n_jobs=-1).fit(X_std, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# новый класс объектов - пайплайн\n",
    "pipe = Pipeline([('standardizer', standardizer), ('knn', knn)])\n",
    "\n",
    "# построим сетку поиска\n",
    "search_space = [{'knn__n_neighbors': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# и обозначим объект класса гридсерч или поиск по сетке\n",
    "clf = GridSearchCV(pipe, search_space, cv=5, verbose=0).fit(X_std, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выведем параметры лучшей модели `best_estimator`\n",
    "clf.best_estimator_.get_params()['knn__n_neighbors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range(1,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(cancer.data, cancer.target, \n",
    "                                                    stratify=cancer.target, random_state=42)\n",
    "\n",
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "\n",
    "#try KNN for diffrent k nearest neighbor from 1 to 15\n",
    "neighbors_setting = range(1,15)\n",
    "\n",
    "for n_neighbors in neighbors_setting:\n",
    "#     print(n_neighbors)\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors)\n",
    "    knn.fit(X_train,y_train)\n",
    "    training_accuracy.append(knn.score(X_train, y_train))\n",
    "    test_accuracy.append(knn.score(X_test, y_test))\n",
    " \n",
    "plt.plot(neighbors_setting, training_accuracy, label='Accuracy of the training set')\n",
    "plt.plot(neighbors_setting, test_accuracy, label='Accuracy of the test set')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Number of Neighbors')\n",
    "plt.legend()\n",
    "\n",
    "#by looking at plot, best result accurs when n_neighbors is 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Как узнать, какие признаки были билее весомые для классификации?\n",
    "\n",
    "В `sklearn` нет реализованого метода подсчета важности признака для этого типа классифкаторов.\n",
    "Существуют методы которые позволяют косвенно оценить значимость признака - убирая его из выборки или заменяя радномными значениями. Или более сложные методы, как https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3281073/ \n",
    "\n",
    "Мы этим заниматься не будем, так как всегда проще интерпретировать модель Логистической регрессии (Линейной регрессии), даже если она немного проигрывает по точности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Самостоятельная работа:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Заполнить пропуски (пример кросс-валидации):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "kfold = StratifiedKFold(n_splits = 10, random_state = 42)\n",
    "X = cancer.data\n",
    "y = cancer.target\n",
    "i = 0\n",
    "\n",
    "for train_index, test_index in kfold.split(X, y):\n",
    "    #(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    <YOUR CODE> # split train nd test\n",
    "    print('Fold #', i)\n",
    "    i+=1\n",
    "    <YOUR CODE> # fit model\n",
    "    print(knn.score(X_test,y_test))\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Повторить эксперимент с регуляризацией (и без на первой выборке) на 5-10 различных разбиениях \n",
    "`random_seed` или на кросс-валидации? (ДЗ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Унести домой: \n",
    "\n",
    "- l1 и l2 нормы для регуляризации\n",
    "- kNN - очень популярный алгоритм в тех случаях, когда объекты сравнимы и имеет место \"похожесть\" объектов.\n",
    "- kNN сильно зависит от метрики. А значит и от масштаба признаков. Перед применением нужно привести признаки к одной шкале\n",
    "- kNN плохо воспринимает большое (>100) количество признаков, т.к. объекты оказываются одинаково отдалены друг от друга в таких пространствах "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
